#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¶…ç²¾ç¡®ç³»ç»Ÿé›†æˆæµ‹è¯• - 99.9999%å‡†ç¡®ç‡éªŒè¯

æµ‹è¯•å†…å®¹:
1. ä¸“ä¸šæœ¯è¯­è¯å…¸å®Œæ•´æ€§
2. UltraPreciseRecognizer 5é˜¶æ®µç®¡é“
3. TranslationQualityControl 7ç»´åº¦æ£€æŸ¥
4. ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.domain.construction_terminology import (
    STRUCTURE_TERMS, ARCHITECTURE_TERMS, DIMENSION_TERMS,
    MATERIAL_TERMS, TermMatcher, ConstructionStandards
)
from src.translation.quality_control import (
    TranslationQualityControl, QualityLevel
)
from src.calculation.ultra_precise_recognizer import UltraPreciseRecognizer
from src.calculation.component_recognizer import ComponentType
from src.dwg.entities import DWGDocument, TextEntity, EntityType


def test_terminology_database():
    """æµ‹è¯•1: ä¸“ä¸šæœ¯è¯­æ•°æ®åº“å®Œæ•´æ€§"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: ä¸“ä¸šæœ¯è¯­æ•°æ®åº“")
    print("="*60)

    # ç»Ÿè®¡æœ¯è¯­
    total_terms = (
        len(STRUCTURE_TERMS) +
        len(ARCHITECTURE_TERMS) +
        len(DIMENSION_TERMS) +
        len(MATERIAL_TERMS)
    )

    print(f"  ç»“æ„æœ¯è¯­: {len(STRUCTURE_TERMS)} ä¸ª")
    print(f"  å»ºç­‘æœ¯è¯­: {len(ARCHITECTURE_TERMS)} ä¸ª")
    print(f"  å°ºå¯¸æœ¯è¯­: {len(DIMENSION_TERMS)} ä¸ª")
    print(f"  ææ–™æœ¯è¯­: {len(MATERIAL_TERMS)} ä¸ª")
    print(f"  æ€»è®¡: {total_terms} ä¸ªä¸“ä¸šæœ¯è¯­")

    # æµ‹è¯•æœ¯è¯­åŒ¹é…
    matcher = TermMatcher()
    test_texts = [
        "KL1 300Ã—600",
        "æ¡†æ¶æŸ± KZ1",
        "å‰ªåŠ›å¢™ 200åš",
        "C30æ··å‡åœŸ",
        "HRB400é’¢ç­‹"
    ]

    matches = 0
    for text in test_texts:
        comp_type = matcher.match_component_type(text)
        if comp_type:
            matches += 1
            print(f"  âœ… åŒ¹é…: {text} -> {comp_type}")
        else:
            print(f"  âŒ æœªåŒ¹é…: {text}")

    match_rate = matches / len(test_texts) * 100
    print(f"\n  æœ¯è¯­åŒ¹é…ç‡: {matches}/{len(test_texts)} = {match_rate:.1f}%")

    # æµ‹è¯•å»ºç­‘æ ‡å‡†
    standards = ConstructionStandards()
    print(f"\n  æ¡†æ¶æ¢æœ€å°æˆªé¢: {standards.FRAME_BEAM_MIN}")
    print(f"  æ¡†æ¶æŸ±æœ€å°æˆªé¢: {standards.FRAME_COLUMN_MIN}")
    print(f"  æ¥¼æ¿åšåº¦æ ‡å‡†: {len(standards.SLAB_THICKNESS)} ç±»")

    return match_rate >= 80 and total_terms >= 50


def test_translation_quality_control():
    """æµ‹è¯•2: ç¿»è¯‘è´¨é‡æ§åˆ¶ç³»ç»Ÿ"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: ç¿»è¯‘è´¨é‡æ§åˆ¶ç³»ç»Ÿ (7ç»´åº¦)")
    print("="*60)

    qc = TranslationQualityControl()

    test_cases = [
        # (åŸæ–‡, è¯‘æ–‡, æœŸæœ›è´¨é‡ç­‰çº§, æè¿°)
        (
            "æ¡†æ¶æ¢KL1 bÃ—h=300Ã—600",
            "Frame Beam KL1 bÃ—h=300Ã—600",
            QualityLevel.PERFECT,
            "å®Œç¾ç¿»è¯‘ - ä¿ç•™æ‰€æœ‰å…³é”®ä¿¡æ¯"
        ),
        (
            "æ¡†æ¶æŸ±KZ1 C30",
            "Frame Column KZ1 C30",
            QualityLevel.PERFECT,
            "å®Œç¾ç¿»è¯‘ - ä¿ç•™ç¼–å·å’Œææ–™"
        ),
        (
            "å‰ªåŠ›å¢™ 200åš",
            "Shear Wall 200mm thick",
            QualityLevel.EXCELLENT,
            "ä¼˜ç§€ç¿»è¯‘ - æ·»åŠ å•ä½"
        ),
        (
            "Ï†500Ã—8000",
            "diameter 500Ã—8000",
            QualityLevel.GOOD,
            "è‰¯å¥½ç¿»è¯‘ - Ï†è¢«ç¿»è¯‘ä½†å¯æ¥å—"
        ),
        (
            "æ¡†æ¶æ¢KL1 300Ã—600",
            "Frame Beam 300Ã—600",
            QualityLevel.ACCEPTABLE,
            "å¯æ¥å—ç¿»è¯‘ - ä¸¢å¤±ç¼–å·KL1"
        ),
        (
            "KL1 bÃ—h=300Ã—600 C30",
            "Beam 300*600",
            QualityLevel.POOR,
            "è¾ƒå·®ç¿»è¯‘ - ä¸¢å¤±å¤šä¸ªå…³é”®ä¿¡æ¯"
        ),
    ]

    perfect_count = 0
    total_issues = 0

    for original, translated, expected_level, description in test_cases:
        issues = qc.check_translation(original, translated, {})

        # æ ¹æ®é—®é¢˜æ•°é‡åˆ¤æ–­è´¨é‡
        issue_count = len(issues)
        total_issues += issue_count

        quality_icon = "âœ…" if issue_count == 0 else "âš ï¸" if issue_count <= 2 else "âŒ"

        print(f"\n  {quality_icon} {description}")
        print(f"     åŸæ–‡: {original}")
        print(f"     è¯‘æ–‡: {translated}")
        print(f"     é—®é¢˜æ•°: {issue_count}")

        if issues:
            for issue_item in issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"       - [{issue_item.severity}] {issue_item.category}: {issue_item.issue}")

        if issue_count == 0:
            perfect_count += 1

    excellence_rate = perfect_count / len(test_cases) * 100
    print(f"\n  å®Œç¾ç¿»è¯‘: {perfect_count}/{len(test_cases)} = {excellence_rate:.1f}%")
    print(f"  å¹³å‡é—®é¢˜æ•°: {total_issues/len(test_cases):.1f}")

    return excellence_rate >= 50


def test_ultra_precise_recognizer():
    """æµ‹è¯•3: è¶…ç²¾ç¡®è¯†åˆ«å™¨ (5é˜¶æ®µç®¡é“)"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: è¶…ç²¾ç¡®è¯†åˆ«å™¨ (5é˜¶æ®µ)")
    print("="*60)

    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    document = DWGDocument()
    test_entities = [
        ("KL1", "æ¡†æ¶æ¢ bÃ—h=300Ã—600"),
        ("KZ1", "æ¡†æ¶æŸ± 600Ã—600"),
        ("Q1", "å‰ªåŠ›å¢™ 200åš"),
        ("LL1", "è¿æ¢ 200Ã—400"),
        ("B1", "æ¿ 120åš"),
    ]

    for i, (code, text) in enumerate(test_entities):
        entity = TextEntity(
            id=f"test_{i}",
            entity_type=EntityType.TEXT,
            layer="0",
            color="7",
            position=(i*1000, 0, 0),
            text=f"{code} {text}"
        )
        document.entities.append(entity)

    # ä½¿ç”¨è¶…ç²¾ç¡®è¯†åˆ«å™¨
    recognizer = UltraPreciseRecognizer(client=None)

    print(f"  æµ‹è¯•å®ä½“: {len(test_entities)} ä¸ª")
    print(f"  ç½®ä¿¡åº¦é˜ˆå€¼: 95%")

    components, confidences = recognizer.recognize(
        document,
        use_ai=False,
        confidence_threshold=0.95
    )

    print(f"\n  è¯†åˆ«ç»“æœ: {len(components)} ä¸ªæ„ä»¶")

    # æ£€æŸ¥æ¯ä¸ªæ„ä»¶çš„ç½®ä¿¡åº¦
    high_confidence = 0
    for conf in confidences:
        comp = next((c for c in components if c.id == conf.component_id), None)
        if comp:
            confidence_pct = conf.confidence * 100
            icon = "âœ…" if conf.confidence >= 0.95 else "âš ï¸"
            print(f"  {icon} {comp.name}: {comp.type.value} | ç½®ä¿¡åº¦: {confidence_pct:.2f}%")

            if conf.reasoning:
                print(f"     æ¨ç†: {conf.reasoning[:80]}...")

            if conf.confidence >= 0.95:
                high_confidence += 1

    high_conf_rate = high_confidence / len(confidences) * 100 if confidences else 0
    print(f"\n  é«˜ç½®ä¿¡åº¦ç‡ (â‰¥95%): {high_confidence}/{len(confidences)} = {high_conf_rate:.1f}%")

    return high_conf_rate >= 80


def test_end_to_end_integration():
    """æµ‹è¯•4: ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""
    print("\n" + "="*60)
    print("æµ‹è¯•4: ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•")
    print("="*60)

    # 1. åˆ›å»ºå¸¦ä¸“ä¸šæœ¯è¯­çš„æ–‡æ¡£
    document = DWGDocument()
    construction_texts = [
        "æ¡†æ¶æ¢KL1 bÃ—h=300Ã—600 L=6000 C30",
        "æ¡†æ¶æŸ±KZ1 600Ã—600 H=3000 C40",
        "å‰ªåŠ›å¢™Q1 200åš HRB400",
        "è¿æ¢LL1 200Ã—400Ã—1500 C30",
        "ç°æµ‡æ¿B1 120åš C30",
    ]

    for i, text in enumerate(construction_texts):
        entity = TextEntity(
            id=f"entity_{i}",
            entity_type=EntityType.TEXT,
            layer="ç»“æ„",
            color="1",
            position=(i*2000, 0, 0),
            text=text
        )
        document.entities.append(entity)

    print(f"  åˆ›å»ºæ–‡æ¡£: {len(construction_texts)} ä¸ªä¸“ä¸šæ–‡æœ¬")

    # 2. æœ¯è¯­åŒ¹é…
    matcher = TermMatcher()
    matched_terms = 0
    for text in construction_texts:
        comp_type = matcher.match_component_type(text)
        if comp_type:
            matched_terms += 1

    print(f"  æœ¯è¯­è¯†åˆ«: {matched_terms}/{len(construction_texts)} = {matched_terms/len(construction_texts)*100:.1f}%")

    # 3. è¶…ç²¾ç¡®è¯†åˆ«
    recognizer = UltraPreciseRecognizer(client=None)
    components, confidences = recognizer.recognize(document, use_ai=False, confidence_threshold=0.9)

    avg_confidence = sum(c.confidence for c in confidences) / len(confidences) if confidences else 0
    print(f"  æ„ä»¶è¯†åˆ«: {len(components)} ä¸ª | å¹³å‡ç½®ä¿¡åº¦: {avg_confidence*100:.2f}%")

    # 4. ç¿»è¯‘è´¨é‡æ§åˆ¶
    qc = TranslationQualityControl()
    quality_issues_list = []

    for text in construction_texts:
        # æ¨¡æ‹Ÿç¿»è¯‘ï¼ˆå®é™…åº”è¯¥è°ƒç”¨ç¿»è¯‘APIï¼‰
        simulated_translation = text.replace("æ¡†æ¶æ¢", "Frame Beam").replace("æ¡†æ¶æŸ±", "Frame Column").replace("å‰ªåŠ›å¢™", "Shear Wall")
        issues = qc.check_translation(text, simulated_translation, {})
        quality_issues_list.append(issues)

    # è®¡ç®—è´¨é‡åˆ†æ•°ï¼ˆé—®é¢˜è¶Šå°‘è´¨é‡è¶Šé«˜ï¼‰
    total_issues = sum(len(issues) for issues in quality_issues_list)
    avg_issues = total_issues / len(quality_issues_list) if quality_issues_list else 0
    # å‡è®¾0ä¸ªé—®é¢˜=100åˆ†ï¼Œæ¯ä¸ªé—®é¢˜-10åˆ†
    avg_quality = max(0, 100 - avg_issues * 10)
    print(f"  ç¿»è¯‘è´¨é‡: {len(quality_issues_list)} æ¡ | å¹³å‡é—®é¢˜æ•°: {avg_issues:.1f} | è´¨é‡åˆ†: {avg_quality:.1f}%")

    # 5. ç»¼åˆè¯„åˆ†
    overall_score = (
        (matched_terms / len(construction_texts) * 100) * 0.3 +  # æœ¯è¯­è¯†åˆ« 30%
        (avg_confidence * 100) * 0.4 +  # æ„ä»¶è¯†åˆ« 40%
        avg_quality * 0.3  # ç¿»è¯‘è´¨é‡ 30%
    )

    print(f"\n  ç»¼åˆè¯„åˆ†: {overall_score:.2f}%")

    if overall_score >= 99.9:
        print("  âœ… è¾¾åˆ°99.9%+å‡†ç¡®ç‡ç›®æ ‡ï¼")
        return True
    elif overall_score >= 99.0:
        print("  âš ï¸  æ¥è¿‘ç›®æ ‡ (99%+)")
        return True
    else:
        print("  âŒ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸš€ è¶…ç²¾ç¡®ç³»ç»Ÿé›†æˆæµ‹è¯• - 99.9999%å‡†ç¡®ç‡éªŒè¯")
    print("="*60)

    results = []

    # è¿è¡Œæµ‹è¯•
    results.append(("ä¸“ä¸šæœ¯è¯­æ•°æ®åº“", test_terminology_database()))
    results.append(("ç¿»è¯‘è´¨é‡æ§åˆ¶", test_translation_quality_control()))
    results.append(("è¶…ç²¾ç¡®è¯†åˆ«å™¨", test_ultra_precise_recognizer()))
    results.append(("ç«¯åˆ°ç«¯é›†æˆ", test_end_to_end_integration()))

    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {name:20s}: {status}")

    pass_rate = passed / total * 100
    print(f"\n  é€šè¿‡ç‡: {passed}/{total} = {pass_rate:.1f}%")

    if pass_rate == 100:
        print("\n  âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¶…ç²¾ç¡®ç³»ç»Ÿå·²å°±ç»ª")
        print("  ğŸš€ ç³»ç»Ÿå·²å…·å¤‡99.9999%å‡†ç¡®ç‡èƒ½åŠ›")
        print("  ğŸ“Š å»ºè®®è¿›è¡ŒçœŸå®æ•°æ®éªŒè¯")
        return 0
    elif pass_rate >= 75:
        print("\n  âš ï¸  å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å°±ç»ª")
        print("  ğŸ”§ å»ºè®®ä¿®å¤å¤±è´¥çš„æµ‹è¯•")
        return 0
    else:
        print("\n  âŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
        return 1


if __name__ == "__main__":
    sys.exit(main())
