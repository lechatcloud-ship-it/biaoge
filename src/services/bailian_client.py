# -*- coding: utf-8 -*-
"""
é˜¿é‡Œäº‘ç™¾ç‚¼å¤§æ¨¡å‹APIå®¢æˆ·ç«¯
ä½¿ç”¨OpenAIå…¼å®¹æ¥å£è°ƒç”¨é€šä¹‰åƒé—®æ¨¡å‹
"""
import os
import time
from typing import List, Dict, Optional
from dataclasses import dataclass
import requests

from ..utils.logger import logger
from ..utils.config_manager import ConfigManager


@dataclass
class TranslationResult:
    """ç¿»è¯‘ç»“æœ"""
    original_text: str
    translated_text: str
    tokens_used: int
    model: str
    cost_estimate: float  # ä¼°ç®—æˆæœ¬ï¼ˆå…ƒï¼‰


class BailianAPIError(Exception):
    """ç™¾ç‚¼APIé”™è¯¯"""
    pass


class BailianClient:
    """é˜¿é‡Œäº‘ç™¾ç‚¼APIå®¢æˆ·ç«¯ - æ”¯æŒå¤šæ¨¡å‹é…ç½®"""

    # æ¨¡å‹å®šä»·ï¼ˆå…ƒ/1000 tokensï¼‰
    PRICING = {
        # é€šç”¨æ¨¡å‹
        'qwen-plus': {'input': 0.004, 'output': 0.004},
        'qwen-max': {'input': 0.040, 'output': 0.040},
        'qwen-turbo': {'input': 0.002, 'output': 0.002},
        # å¤šæ¨¡æ€æ¨¡å‹
        'qwen-vl-max': {'input': 0.020, 'output': 0.020},
        'qwen-vl-plus': {'input': 0.008, 'output': 0.008},
        # ç¿»è¯‘ä¸“ç”¨æ¨¡å‹
        'qwen-mt-plus': {'input': 0.006, 'output': 0.006},
        'qwen-mt-turbo': {'input': 0.003, 'output': 0.003},
        'qwen-mt-image': {'input': 0.012, 'output': 0.012},
        # æ·±åº¦æ€è€ƒæ¨¡å‹
        'qwen3-max': {'input': 0.040, 'output': 0.040},
        'qwq-max-preview': {'input': 0.040, 'output': 0.040},
    }

    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None):
        """
        åˆå§‹åŒ–ç™¾ç‚¼å®¢æˆ·ç«¯

        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡DASHSCOPE_API_KEYè¯»å–
            model: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
        """
        self.api_key = api_key or os.getenv('DASHSCOPE_API_KEY')
        if not self.api_key:
            raise BailianAPIError(
                "æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡DASHSCOPE_API_KEYæˆ–ä¼ å…¥api_keyå‚æ•°"
            )

        config = ConfigManager()

        # ä»é…ç½®è¯»å–æ¨¡å‹è®¾ç½®
        self.use_custom_model = config.get('api.use_custom_model', False)
        self.custom_model = config.get('api.custom_model', '')

        # è¯»å–ä¸åŒä»»åŠ¡çš„æ¨¡å‹é…ç½®
        self.multimodal_model = config.get('api.multimodal_model', 'qwen-vl-plus')
        self.image_model = config.get('api.image_model', 'qwen-vl-plus')
        self.text_model = config.get('api.text_model', 'qwen-mt-plus')
        self.calculation_model = config.get('api.calculation_model', 'qwen-max')  # ğŸ†• ç®—é‡ä¸“ç”¨æ¨¡å‹

        # å¦‚æœä¼ å…¥äº†modelå‚æ•°ï¼Œä½¿ç”¨ä¼ å…¥çš„å€¼
        if model:
            self.text_model = model

        self.endpoint = config.get('api.endpoint', 'https://dashscope.aliyuncs.com')
        self.base_url = f"{self.endpoint}/compatible-mode/v1"
        self.timeout = config.get('api.timeout', 60)
        self.max_retries = config.get('api.max_retries', 3)

        logger.info(
            f"ç™¾ç‚¼å®¢æˆ·ç«¯åˆå§‹åŒ– - "
            f"æ–‡æœ¬æ¨¡å‹: {self.text_model}, "
            f"å›¾ç‰‡æ¨¡å‹: {self.image_model}, "
            f"å¤šæ¨¡æ€: {self.multimodal_model}, "
            f"ç®—é‡æ¨¡å‹: {self.calculation_model}, "  # ğŸ†•
            f"è‡ªå®šä¹‰æ¨¡å‹: {self.use_custom_model}"
        )

    def get_model_for_task(self, task_type: str = 'text') -> str:
        """
        æ ¹æ®ä»»åŠ¡ç±»å‹è·å–åˆé€‚çš„æ¨¡å‹

        Args:
            task_type: ä»»åŠ¡ç±»å‹ - 'text'(æ–‡æœ¬ç¿»è¯‘), 'image'(å›¾ç‰‡ç¿»è¯‘), 'multimodal'(å¤šæ¨¡æ€), 'calculation'(å·¥ç¨‹é‡è®¡ç®—)

        Returns:
            str: æ¨¡å‹åç§°
        """
        # å¦‚æœå¯ç”¨äº†è‡ªå®šä¹‰æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨
        if self.use_custom_model and self.custom_model:
            return self.custom_model

        # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ¨¡å‹
        if task_type == 'image':
            return self.image_model
        elif task_type == 'multimodal':
            return self.multimodal_model
        elif task_type == 'calculation':  # ğŸ†• å·¥ç¨‹é‡è®¡ç®—ä»»åŠ¡
            return self.calculation_model
        else:
            return self.text_model
    
    def translate_text(
        self,
        text: str,
        from_lang: str,
        to_lang: str,
        context: Optional[str] = None,
        task_type: str = 'text'
    ) -> TranslationResult:
        """
        ç¿»è¯‘å•ä¸ªæ–‡æœ¬

        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            from_lang: æºè¯­è¨€ï¼ˆå¦‚ï¼šä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ï¼‰
            to_lang: ç›®æ ‡è¯­è¨€
            context: ä¸Šä¸‹æ–‡æç¤ºï¼ˆå¯é€‰ï¼‰
            task_type: ä»»åŠ¡ç±»å‹ - 'text'(æ–‡æœ¬ç¿»è¯‘), 'image'(å›¾ç‰‡ç¿»è¯‘), 'multimodal'(å¤šæ¨¡æ€)

        Returns:
            TranslationResult: ç¿»è¯‘ç»“æœ
        """
        # é€‰æ‹©åˆé€‚çš„æ¨¡å‹
        model = self.get_model_for_task(task_type)

        # æ„å»ºprompt
        system_prompt = self._build_translation_prompt(from_lang, to_lang, context)

        # è°ƒç”¨API
        messages = [
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': text}
        ]

        response = self._call_api(messages, model)

        return TranslationResult(
            original_text=text,
            translated_text=response['translated_text'],
            tokens_used=response['tokens_used'],
            model=model,
            cost_estimate=response['cost_estimate']
        )
    
    def translate_batch(
        self,
        texts: List[str],
        from_lang: str,
        to_lang: str,
        context: Optional[str] = None,
        task_type: str = 'text'
    ) -> List[TranslationResult]:
        """
        æ‰¹é‡ç¿»è¯‘æ–‡æœ¬ï¼ˆä¸€æ¬¡APIè°ƒç”¨ï¼‰

        Args:
            texts: è¦ç¿»è¯‘çš„æ–‡æœ¬åˆ—è¡¨
            from_lang: æºè¯­è¨€
            to_lang: ç›®æ ‡è¯­è¨€
            context: ä¸Šä¸‹æ–‡æç¤º
            task_type: ä»»åŠ¡ç±»å‹ - 'text'(æ–‡æœ¬ç¿»è¯‘), 'image'(å›¾ç‰‡ç¿»è¯‘), 'multimodal'(å¤šæ¨¡æ€)

        Returns:
            List[TranslationResult]: ç¿»è¯‘ç»“æœåˆ—è¡¨
        """
        if not texts:
            return []

        # é€‰æ‹©åˆé€‚çš„æ¨¡å‹
        model = self.get_model_for_task(task_type)

        # æ„å»ºæ‰¹é‡ç¿»è¯‘prompt
        system_prompt = self._build_batch_translation_prompt(from_lang, to_lang, context)

        # æ„å»ºæ‰¹é‡æ–‡æœ¬ï¼ˆå¸¦ç¼–å·ï¼‰
        numbered_texts = '\n'.join([f"{i+1}. {text}" for i, text in enumerate(texts)])

        messages = [
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': numbered_texts}
        ]

        response = self._call_api(messages, model)

        # è§£ææ‰¹é‡ç¿»è¯‘ç»“æœ
        translated_texts = self._parse_batch_response(response['translated_text'], len(texts))

        # è®¡ç®—å•ä¸ªæ–‡æœ¬çš„tokenæ¶ˆè€—ï¼ˆå¹³å‡åˆ†é…ï¼‰
        tokens_per_text = response['tokens_used'] // len(texts)
        cost_per_text = response['cost_estimate'] / len(texts)

        results = []
        for original, translated in zip(texts, translated_texts):
            results.append(TranslationResult(
                original_text=original,
                translated_text=translated,
                tokens_used=tokens_per_text,
                model=model,
                cost_estimate=cost_per_text
            ))

        return results
    
    def _call_api(self, messages: List[Dict[str, str]], model: str) -> Dict:
        """
        è°ƒç”¨APIï¼ˆå¸¦é‡è¯•ï¼‰

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            model: è¦ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            Dict: åŒ…å«translated_text, tokens_used, cost_estimateçš„å­—å…¸
        """
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        payload = {
            'model': model,
            'messages': messages
        }
        
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    json=payload,
                    headers=headers,
                    timeout=self.timeout
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # æå–ç»“æœ
                    translated_text = data['choices'][0]['message']['content']
                    tokens_used = data['usage']['total_tokens']
                    
                    # è®¡ç®—æˆæœ¬
                    input_tokens = data['usage']['prompt_tokens']
                    output_tokens = data['usage']['completion_tokens']
                    pricing = self.PRICING.get(model, self.PRICING['qwen-plus'])
                    cost_estimate = (
                        input_tokens * pricing['input'] / 1000 +
                        output_tokens * pricing['output'] / 1000
                    )
                    
                    logger.debug(
                        f"APIè°ƒç”¨æˆåŠŸ: tokens={tokens_used}, cost=Â¥{cost_estimate:.4f}"
                    )
                    
                    return {
                        'translated_text': translated_text.strip(),
                        'tokens_used': tokens_used,
                        'cost_estimate': cost_estimate
                    }
                
                elif response.status_code == 401:
                    raise BailianAPIError(
                        "APIå¯†é’¥éªŒè¯å¤±è´¥\n\n"
                        "å¯èƒ½çš„åŸå› ï¼š\n"
                        "1. APIå¯†é’¥æœªè®¾ç½®æˆ–å·²è¿‡æœŸ\n"
                        "2. ç¯å¢ƒå˜é‡DASHSCOPE_API_KEYé…ç½®é”™è¯¯\n\n"
                        "è§£å†³æ–¹æ³•ï¼š\n"
                        "è¯·å‰å¾€é˜¿é‡Œäº‘æ§åˆ¶å°è·å–æœ‰æ•ˆçš„APIå¯†é’¥ï¼Œå¹¶æ­£ç¡®é…ç½®ç¯å¢ƒå˜é‡"
                    )

                elif response.status_code == 429:
                    # é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…åé‡è¯•
                    wait_time = 2 ** attempt
                    logger.warning(f"è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œ{wait_time}ç§’åè‡ªåŠ¨é‡è¯•...")
                    time.sleep(wait_time)
                    continue

                elif response.status_code == 400:
                    raise BailianAPIError(
                        "è¯·æ±‚å‚æ•°é”™è¯¯\n\n"
                        "å¯èƒ½çš„åŸå› ï¼š\n"
                        "1. æ–‡æœ¬å†…å®¹æ ¼å¼ä¸æ­£ç¡®\n"
                        "2. æ¨¡å‹å‚æ•°é…ç½®æœ‰è¯¯\n\n"
                        "å»ºè®®ï¼šè¯·æ£€æŸ¥è¾“å…¥å†…å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚"
                    )

                elif response.status_code == 500:
                    error_msg = response.text
                    logger.error(f"æœåŠ¡å™¨é”™è¯¯: {error_msg}")
                    last_error = BailianAPIError(
                        "é˜¿é‡Œäº‘æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n\n"
                        "è¿™é€šå¸¸æ˜¯ä¸´æ—¶æ€§é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•\n"
                        "å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·è”ç³»é˜¿é‡Œäº‘æŠ€æœ¯æ”¯æŒ"
                    )

                else:
                    error_msg = response.text
                    logger.error(f"APIè°ƒç”¨å¤±è´¥ (HTTP {response.status_code}): {error_msg}")
                    last_error = BailianAPIError(
                        f"ç¿»è¯‘æœåŠ¡è¯·æ±‚å¤±è´¥ (é”™è¯¯ç : {response.status_code})\n\n"
                        f"è¯¦ç»†ä¿¡æ¯ï¼š{error_msg[:200]}\n\n"
                        "å»ºè®®ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
                    )
            
            except requests.Timeout as e:
                logger.error(f"è¯·æ±‚è¶…æ—¶: {e}")
                last_error = BailianAPIError(
                    "ç½‘ç»œè¯·æ±‚è¶…æ—¶\n\n"
                    "å¯èƒ½çš„åŸå› ï¼š\n"
                    "1. ç½‘ç»œè¿æ¥ä¸ç¨³å®š\n"
                    "2. ç¿»è¯‘å†…å®¹è¿‡å¤šï¼Œå¤„ç†æ—¶é—´è¾ƒé•¿\n\n"
                    "å»ºè®®ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"
                )

                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.info(f"{wait_time}ç§’åè‡ªåŠ¨é‡è¯•...")
                    time.sleep(wait_time)

            except requests.ConnectionError as e:
                logger.error(f"è¿æ¥å¤±è´¥: {e}")
                last_error = BailianAPIError(
                    "æ— æ³•è¿æ¥åˆ°ç¿»è¯‘æœåŠ¡\n\n"
                    "å¯èƒ½çš„åŸå› ï¼š\n"
                    "1. ç½‘ç»œè¿æ¥æ–­å¼€\n"
                    "2. é˜²ç«å¢™é˜»æ­¢äº†è¿æ¥\n"
                    "3. ä»£ç†è®¾ç½®ä¸æ­£ç¡®\n\n"
                    "å»ºè®®ï¼šè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®åé‡è¯•"
                )

                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.info(f"{wait_time}ç§’åè‡ªåŠ¨é‡è¯•...")
                    time.sleep(wait_time)

            except requests.RequestException as e:
                logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
                last_error = BailianAPIError(
                    f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸\n\n"
                    f"é”™è¯¯ä¿¡æ¯ï¼š{str(e)[:200]}\n\n"
                    "å»ºè®®ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
                )

                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.info(f"{wait_time}ç§’åè‡ªåŠ¨é‡è¯•...")
                    time.sleep(wait_time)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise last_error or BailianAPIError(
            "ç¿»è¯‘è¯·æ±‚å¤±è´¥\n\n"
            f"å·²å°è¯•{self.max_retries}æ¬¡é‡è¯•ï¼Œä½†ä»ç„¶å¤±è´¥\n"
            "å»ºè®®ï¼š\n"
            "1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n"
            "2. ç¡®è®¤APIå¯†é’¥é…ç½®æ­£ç¡®\n"
            "3. ç¨åå†è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ"
        )
    
    def _build_translation_prompt(
        self,
        from_lang: str,
        to_lang: str,
        context: Optional[str] = None
    ) -> str:
        """æ„å»ºç¿»è¯‘prompt - äººå·¥çº§åˆ«ç¿»è¯‘è´¨é‡"""
        base_prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šå»ºç­‘å·¥ç¨‹CADå›¾çº¸çš„èµ„æ·±ç¿»è¯‘ä¸“å®¶ï¼Œæ‹¥æœ‰15å¹´ä»¥ä¸Šçš„ä¸“ä¸šç»éªŒã€‚

ã€ç¿»è¯‘ä»»åŠ¡ã€‘å°†ä»¥ä¸‹{from_lang}æ–‡æœ¬ç¿»è¯‘æˆ{to_lang}

ã€ä¸“ä¸šè¦æ±‚ã€‘
1. **æœ¯è¯­å‡†ç¡®æ€§**ï¼šä¸¥æ ¼ä½¿ç”¨å»ºç­‘ã€ç»“æ„ã€æœºæ¢°ã€ç”µæ°”ç­‰é¢†åŸŸçš„æ ‡å‡†æœ¯è¯­
   - å»ºç­‘æ„ä»¶ï¼šæ¢(beam)ã€æŸ±(column)ã€å¢™(wall)ã€æ¿(slab)ç­‰
   - ææ–™è§„æ ¼ï¼šæ··å‡åœŸæ ‡å·(C20/C30)ã€é’¢ç­‹å‹å·(HRB400)ç­‰
   - å°ºå¯¸å•ä½ï¼šä¿æŒmmã€mã€Ã—ã€Î¦ç­‰ç¬¦å·ä¸å˜

2. **æ•°å­—å’Œç¬¦å·**ï¼š
   - ç»å¯¹ä¿ç•™æ‰€æœ‰æ•°å­—ã€å°ºå¯¸ã€ç¼–å·
   - ä¿æŒå•ä½ç¬¦å·ã€ç‰¹æ®Šå­—ç¬¦ä¸å˜
   - ç»´æŒåŸæ–‡æ ¼å¼ï¼ˆå¦‚ï¼š300Ã—600ä¸å¯æ”¹ä¸º300*600ï¼‰

3. **ä¸“ä¸šè§„èŒƒ**ï¼š
   - éµå¾ªå›½å®¶å»ºç­‘åˆ¶å›¾æ ‡å‡†(GB/T 50001)
   - ä½¿ç”¨è¡Œä¸šé€šç”¨ç¼©å†™ï¼šKL(æ¡†æ¶æ¢)ã€KZ(æ¡†æ¶æŸ±)ç­‰
   - ä¿æŒä¸“ä¸šå‘½åè§„èŒƒæ€§

4. **ç¿»è¯‘é£æ ¼**ï¼š
   - ç®€æ´ä¸“ä¸šï¼Œç¬¦åˆå›¾çº¸æ ‡æ³¨ä¹ æƒ¯
   - é¿å…å£è¯­åŒ–è¡¨è¾¾
   - ä¸æ·»åŠ è§£é‡Šæ€§æ–‡å­—

5. **è¾“å‡ºæ ¼å¼**ï¼šåªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹"""

        if context:
            base_prompt += f"\n\nã€ä¸Šä¸‹æ–‡å‚è€ƒã€‘{context}"

        return base_prompt
    
    def _build_batch_translation_prompt(
        self,
        from_lang: str,
        to_lang: str,
        context: Optional[str] = None
    ) -> str:
        """æ„å»ºæ‰¹é‡ç¿»è¯‘prompt - äººå·¥çº§åˆ«ç¿»è¯‘è´¨é‡"""
        base_prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šå»ºç­‘å·¥ç¨‹CADå›¾çº¸çš„èµ„æ·±ç¿»è¯‘ä¸“å®¶ï¼Œæ‹¥æœ‰15å¹´ä»¥ä¸Šçš„ä¸“ä¸šç»éªŒã€‚

ã€æ‰¹é‡ç¿»è¯‘ä»»åŠ¡ã€‘æˆ‘å°†æä¾›ä¸€æ‰¹{from_lang}æ–‡æœ¬ï¼ˆå¸¦ç¼–å·ï¼‰ï¼Œè¯·ç¿»è¯‘æˆ{to_lang}

ã€ä¸“ä¸šè¦æ±‚ã€‘
1. **æœ¯è¯­å‡†ç¡®æ€§**ï¼šä¸¥æ ¼ä½¿ç”¨å»ºç­‘ã€ç»“æ„ã€æœºæ¢°ã€ç”µæ°”ç­‰é¢†åŸŸçš„æ ‡å‡†æœ¯è¯­
   - å»ºç­‘æ„ä»¶ï¼šæ¢(beam)ã€æŸ±(column)ã€å¢™(wall)ã€æ¿(slab)ã€é—¨(door)ã€çª—(window)
   - ææ–™è§„æ ¼ï¼šC20/C30æ··å‡åœŸã€Q235/Q345é’¢æã€HRB400é’¢ç­‹
   - ä¿æŒä¸“ä¸šç¼©å†™ï¼šKL(æ¡†æ¶æ¢)ã€KZ(æ¡†æ¶æŸ±)ã€NQ(å†…å¢™)ã€WQ(å¤–å¢™)

2. **æ•°å­—å’Œç¬¦å·**ï¼š
   - ç»å¯¹ä¿ç•™æ‰€æœ‰æ•°å­—ã€å°ºå¯¸ã€ç¼–å·
   - ä¿æŒå•ä½ç¬¦å·ä¸å˜ï¼šmmã€mã€Ã—ã€Î¦ã€@ç­‰
   - ç»´æŒåŸæ–‡æ ¼å¼ï¼ˆå¦‚ï¼š300Ã—600Ã—200ï¼‰

3. **è¾“å‡ºæ ¼å¼**ï¼š
   - æ¯æ¡ç¿»è¯‘ç‹¬ç«‹æˆè¡Œ
   - æ ¼å¼ï¼š"ç¼–å·. ç¿»è¯‘ç»“æœ"
   - ä¸¥æ ¼æŒ‰åŸç¼–å·é¡ºåº
   - ä¸æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜

4. **ä¸“ä¸šè§„èŒƒ**ï¼š
   - éµå¾ªå›½å®¶å»ºç­‘åˆ¶å›¾æ ‡å‡†
   - ä¿æŒå›¾çº¸æ ‡æ³¨çš„ç®€æ´æ€§
   - ä½¿ç”¨è¡Œä¸šé€šç”¨è¡¨è¾¾æ–¹å¼"""

        if context:
            base_prompt += f"\n\nã€ä¸Šä¸‹æ–‡å‚è€ƒã€‘{context}"

        return base_prompt
    
    def _parse_batch_response(self, response: str, expected_count: int) -> List[str]:
        """
        è§£ææ‰¹é‡ç¿»è¯‘å“åº”
        
        Args:
            response: APIè¿”å›çš„æ‰¹é‡ç¿»è¯‘æ–‡æœ¬
            expected_count: æœŸæœ›çš„ç¿»è¯‘æ•°é‡
        
        Returns:
            List[str]: ç¿»è¯‘ç»“æœåˆ—è¡¨
        """
        lines = response.strip().split('\n')
        translations = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # å°è¯•è§£æ "ç¼–å·. ç¿»è¯‘æ–‡æœ¬" æ ¼å¼
            if '. ' in line:
                _, text = line.split('. ', 1)
                translations.append(text.strip())
            else:
                # å¦‚æœæ²¡æœ‰ç¼–å·ï¼Œç›´æ¥ä½¿ç”¨
                translations.append(line)
        
        # å¦‚æœè§£æç»“æœæ•°é‡ä¸åŒ¹é…ï¼Œè®°å½•è­¦å‘Š
        if len(translations) != expected_count:
            logger.warning(
                f"æ‰¹é‡ç¿»è¯‘ç»“æœæ•°é‡ä¸åŒ¹é…: æœŸæœ›{expected_count}, å®é™…{len(translations)}"
            )
        
        return translations

    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: Optional[str] = None,
        temperature: float = 0.7,
        top_p: float = 0.9,
        tools: Optional[List[Dict]] = None,
        stream: bool = False,
        enable_thinking: bool = False,
        thinking_budget: Optional[int] = None
    ) -> Dict:
        """
        é€šç”¨å¯¹è¯è¡¥å…¨API (æ”¯æŒæµå¼ã€æ·±åº¦æ€è€ƒã€å·¥å…·è°ƒç”¨)

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨qwen-max
            temperature: æ¸©åº¦å‚æ•° (0-2)ï¼Œæ§åˆ¶éšæœºæ€§
            top_p: æ ¸é‡‡æ ·å‚æ•° (0-1)
            tools: å·¥å…·å®šä¹‰åˆ—è¡¨ï¼ˆFunction Callingï¼‰
            stream: æ˜¯å¦æµå¼è¾“å‡º
            enable_thinking: æ˜¯å¦å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼
            thinking_budget: æ€è€ƒè¿‡ç¨‹çš„æœ€å¤§tokenæ•°

        Returns:
            Dict: APIå“åº”æ•°æ®
        """
        if model is None:
            model = 'qwen-max'

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        payload = {
            'model': model,
            'messages': messages,
            'temperature': temperature,
            'top_p': top_p,
        }

        # æµå¼è¾“å‡º
        if stream:
            payload['stream'] = True
            payload['stream_options'] = {"include_usage": True}

        # å·¥å…·è°ƒç”¨
        if tools:
            payload['tools'] = tools

        # æ·±åº¦æ€è€ƒæ¨¡å¼ï¼ˆé€šè¿‡extra_bodyä¼ é€’ï¼‰
        if enable_thinking:
            if 'extra_body' not in payload:
                payload['extra_body'] = {}
            payload['extra_body']['enable_thinking'] = True
            if thinking_budget:
                payload['extra_body']['thinking_budget'] = thinking_budget

        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                json=payload,
                headers=headers,
                timeout=self.timeout,
                stream=stream  # æµå¼è¯·æ±‚
            )

            if response.status_code == 200:
                if stream:
                    # è¿”å›æµå¼å“åº”è¿­ä»£å™¨
                    return {'stream': response.iter_lines(decode_unicode=True)}
                else:
                    # è¿”å›å®Œæ•´å“åº”
                    return response.json()
            else:
                error_msg = response.text
                logger.error(f"å¯¹è¯APIè°ƒç”¨å¤±è´¥ (HTTP {response.status_code}): {error_msg}")
                raise BailianAPIError(f"å¯¹è¯è¯·æ±‚å¤±è´¥: {error_msg}")

        except requests.Timeout:
            raise BailianAPIError("å¯¹è¯è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except requests.ConnectionError:
            raise BailianAPIError("æ— æ³•è¿æ¥åˆ°å¯¹è¯æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ")
        except Exception as e:
            logger.error(f"å¯¹è¯APIå¼‚å¸¸: {e}", exc_info=True)
            raise BailianAPIError(f"å¯¹è¯APIå¼‚å¸¸: {str(e)}")

    def chat_stream(
        self,
        messages: List[Dict[str, str]],
        model: Optional[str] = None,
        temperature: float = 0.7,
        top_p: float = 0.9,
        enable_thinking: bool = False
    ):
        """
        æµå¼å¯¹è¯ï¼ˆç”Ÿæˆå™¨ï¼‰

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            model: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
            top_p: æ ¸é‡‡æ ·å‚æ•°
            enable_thinking: æ˜¯å¦å¯ç”¨æ·±åº¦æ€è€ƒ

        Yields:
            Dict: æ¯ä¸ªæµå¼å“åº”å—
        """
        response = self.chat_completion(
            messages=messages,
            model=model,
            temperature=temperature,
            top_p=top_p,
            stream=True,
            enable_thinking=enable_thinking
        )

        import json

        for line in response['stream']:
            if not line:
                continue

            # è·³è¿‡æ³¨é‡Šè¡Œ
            if line.startswith(':'):
                continue

            # è§£æSSEæ ¼å¼ï¼šdata: {...}
            if line.startswith('data: '):
                data_str = line[6:]  # ç§»é™¤ "data: " å‰ç¼€

                # ç»“æŸæ ‡è®°
                if data_str == '[DONE]':
                    break

                try:
                    data = json.loads(data_str)
                    yield data
                except json.JSONDecodeError as e:
                    logger.warning(f"è§£ææµå¼å“åº”å¤±è´¥: {e}, line: {data_str[:100]}")
                    continue

    def test_connection(self) -> bool:
        """
        æµ‹è¯•APIè¿æ¥

        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            result = self.translate_text("æµ‹è¯•", "ä¸­æ–‡", "è‹±æ–‡", task_type='text')
            logger.info(f"APIè¿æ¥æµ‹è¯•æˆåŠŸ: {result.original_text} -> {result.translated_text} (æ¨¡å‹: {result.model})")
            return True
        except Exception as e:
            logger.error(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
